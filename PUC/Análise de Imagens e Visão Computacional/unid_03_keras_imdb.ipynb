{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"unidade03_keras_imdb.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMfQnjJEIxshgukl5pXv8YS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"G26TeWKT5yRV","colab_type":"text"},"source":["Neste exemplo você irá construir um classificador binário para o dataset do IMDB (NLP Problem)"]},{"cell_type":"markdown","metadata":{"id":"uivPCP-y7OX_","colab_type":"text"},"source":["O imdb dataset já vem com o Keras e já é pré-processado. Os reviews (sequência de palavras) já estão organizados em sequências de inteiros, em que cada inteiro significa uma palavra específica no dicionário.\n"]},{"cell_type":"code","metadata":{"id":"vaiSFoNw7Tap","colab_type":"code","colab":{}},"source":["from keras.datasets import imdb"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kZ-PM9un7aoV","colab_type":"text"},"source":["As 10000 palavras mais frequentes serão mantidas no dataset"]},{"cell_type":"code","metadata":{"id":"9zIEOFZD7WzS","colab_type":"code","colab":{}},"source":["# call load_data with allow_pickle implicitly set to true\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Czjg_p-7h8L","colab_type":"text"},"source":["Train_data e test_data são as listas de reviews, cada review é uma lista de índices de palavras (texto do review codificado no índice de palavras)\n"]},{"cell_type":"code","metadata":{"id":"cE4gMouj7iyg","colab_type":"code","colab":{}},"source":["print(train_data[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M4kimfA97pUD","colab_type":"text"},"source":["Train_labels e test_labels são as listas de 0’s e 1’s (0 = negativo review e 1 = positivo review)\n"]},{"cell_type":"code","metadata":{"id":"fxiSXNaA7qAO","colab_type":"code","colab":{}},"source":["print(train_labels[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ph-hiD5b7uzh","colab_type":"text"},"source":["Veja que nenhum índice de palavra irá exceder 10000"]},{"cell_type":"code","metadata":{"id":"fd_Sqcyq7v1K","colab_type":"code","colab":{}},"source":["max([max(sequence) for sequence in train_data])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R8Y5vzYmbZyu","colab_type":"text"},"source":["Não podemos inserir um lista de inteiros na rede. Temos que converter a listar para um tensor no formato (samples, word_indices)\n","\n","Por exemplo, transformar a sequência [3, 5] em um vetor de 10.000 dimensões que seria todos os 0s, exceto os índices 3 e 5, que seriam 1s."]},{"cell_type":"code","metadata":{"id":"5rElazRb727e","colab_type":"code","colab":{}},"source":["import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3krBFRu174zb","colab_type":"code","colab":{}},"source":["def vectorize_sequences(sequences, dimension=10000):\n","  # Creates an all-zero matrix of shape (len(sequences), dimension)\n","  results = np.zeros((len(sequences), dimension))\n","\n","  for i, sequence in enumerate(sequences):\n","    # Sets specific indices of results[i] to 1s\n","    results[i, sequence] = 1.\n","\n","  return results"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgHczT5U7_jO","colab_type":"code","colab":{}},"source":["x_train = vectorize_sequences(train_data)\n","x_test = vectorize_sequences(test_data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z9HlCFIy8Ek7","colab_type":"text"},"source":["O mesmo para os vetores de labels\n"]},{"cell_type":"code","metadata":{"id":"msXzaOO18FN7","colab_type":"code","colab":{}},"source":["y_train = np.asarray(train_labels).astype('float32')\n","y_test = np.asarray(test_labels).astype('float32')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t7VQBVAZxjy2","colab_type":"text"},"source":["**Construindo a rede**"]},{"cell_type":"markdown","metadata":{"id":"EYy49mi88gAi","colab_type":"text"},"source":["O input é um vetor e os labels são escalares (1’s e 0’s). Vamos usar um fully connected (Dense) com relu como activation function.\n","\n","Dense(16, activation='relu’)\n","\n","16: é o argumento para cada dense layer. Ou seja, é o número de hidden units da camada (é a dimensão da representação da camada). \n"]},{"cell_type":"markdown","metadata":{"id":"uzAKlWUE8lqs","colab_type":"text"},"source":["**Configurando a rede**\n","\n","Iremos configurar a rede com duas camadas intermediárias com 16 unidades ocultas cada.\n","Uma terceira camada que produzirá a previsão escalar em relação ao sentimento do review em questão"]},{"cell_type":"code","metadata":{"id":"v0G2rqdM8oAA","colab_type":"code","colab":{}},"source":["from keras import models\n","from keras import layers\n","\n","model = models.Sequential()\n","model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n","model.add(layers.Dense(16, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q25E50xQ8tjE","colab_type":"text"},"source":["Escolhendo a loss function e o optimizer (como strings por já fazerem parte do Keras)\n"]},{"cell_type":"code","metadata":{"id":"NFeKYO458vO8","colab_type":"code","colab":{}},"source":["from keras import losses\n","from keras import metrics\n","from keras.optimizers import SGD, RMSprop\n","\n","model.compile(optimizer=RMSprop(lr=0.001),\n","loss=losses.binary_crossentropy,\n","metrics=[metrics.binary_accuracy])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yDUn6frW88aV","colab_type":"text"},"source":["No entanto, você pode deixar tudo como padrão:"]},{"cell_type":"code","metadata":{"id":"ruuflKQK89Xl","colab_type":"code","colab":{}},"source":["model.compile(optimizer='rmsprop',\n","loss='binary_crossentropy',\n","metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"etCwaa9I82e2","colab_type":"text"},"source":["Para monitorar o treinamento, criamos o conjunto de validação separando 10000 amostras do conjunto original"]},{"cell_type":"code","metadata":{"id":"FD7ryltp83qq","colab_type":"code","colab":{}},"source":["x_val = x_train[:10000]\n","partial_x_train = x_train[10000:]\n","y_val = y_train[:10000]\n","partial_y_train = y_train[10000:]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2zIqCQ7Q9DaU","colab_type":"text"},"source":["Iremos treinar o modelo por 20 épocas (20 iterações sobre todas as amostras do treinamento) em um batch de 512 amostras.\n"]},{"cell_type":"code","metadata":{"id":"2jKr6P9R9EPu","colab_type":"code","colab":{}},"source":["model.fit(partial_x_train,\n","partial_y_train,\n","epochs=20,\n","batch_size=512,\n","validation_data=(x_val, y_val))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NAIx01De2iEH","colab_type":"text"},"source":["**Usando uma rede treinada para gerar previsões sobre novos dados**\n","\n","Gerando a probabilidade de cada análise ser positiva com o método predict"]},{"cell_type":"code","metadata":{"id":"AblWlU902Vwi","colab_type":"code","colab":{}},"source":["print(model.predict(x_test))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mfh7Wnke2yCd","colab_type":"text"},"source":["A rede está confiante para algumas amostras (0,99 ou mais, ou 0,01 ou menos), mas menos confiante para outras (0,6, 0,4)."]},{"cell_type":"markdown","metadata":{"id":"pXj1c-Qc9klv","colab_type":"text"},"source":["**Treinando o modelo do zero**"]},{"cell_type":"code","metadata":{"id":"lQyrpyMDakZX","colab_type":"code","colab":{}},"source":["model = models.Sequential()\n","model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n","model.add(layers.Dense(16, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RvWpyiCEal0f","colab_type":"code","colab":{}},"source":["model.compile(optimizer='rmsprop',\n","loss='binary_crossentropy',\n","metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaQ7Kijk9myU","colab_type":"code","colab":{}},"source":["model.fit(x_train, y_train, epochs=4, batch_size=512)\n","results = model.evaluate(x_test, y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2oNmOQZIrW38","colab_type":"text"},"source":["Referência: François Chollet. Deep Learning with Python. November 2017  "]}]}