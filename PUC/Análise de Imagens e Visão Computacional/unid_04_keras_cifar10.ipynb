{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"unidade04_keras_cifar10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN9AiSO9RdR5fF+F2Pl7TS6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Jw97y8m-LCQg","colab_type":"text"},"source":["CNN para classificar imagens do banco de dados CIFAR-10.\n","\n","1. Load CIFAR-10 Database"]},{"cell_type":"code","metadata":{"id":"aLm71fvnCZQR","colab_type":"code","colab":{}},"source":["import keras\n","from keras.datasets import cifar10\n","\n","# load the pre-shuffled train and test data\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"syL3h2i6LKcb","colab_type":"text"},"source":["2. Visualize the First 24 Training Images"]},{"cell_type":"code","metadata":{"id":"gjwuK9B9LK-A","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","fig = plt.figure(figsize=(20,5))\n","for i in range(36):\n","    ax = fig.add_subplot(3, 12, i + 1, xticks=[], yticks=[])\n","    ax.imshow(np.squeeze(x_train[i]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kbCXp7cfLNoS","colab_type":"text"},"source":["3. Rescale the Images by Dividing Every Pixel in Every Image by 255"]},{"cell_type":"code","metadata":{"id":"cMjEcB4dLV5O","colab_type":"code","colab":{}},"source":["# rescale [0,255] --> [0,1]\n","x_train = x_train.astype('float32')/255\n","x_test = x_test.astype('float32')/255"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xKdBVaGALawZ","colab_type":"text"},"source":["4. Break Dataset into Training, Testing, and Validation Sets"]},{"cell_type":"code","metadata":{"id":"ZyKgd_XYLY0K","colab_type":"code","colab":{}},"source":["from keras.utils import np_utils\n","\n","# one-hot encode the labels\n","num_classes = len(np.unique(y_train))\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","# break training set into training and validation sets\n","(x_train, x_valid) = x_train[5000:], x_train[:5000]\n","(y_train, y_valid) = y_train[5000:], y_train[:5000]\n","\n","# print shape of training set\n","print('x_train shape:', x_train.shape)\n","\n","# print number of training, validation, and test images\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","print(x_valid.shape[0], 'validation samples')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mHduDviHLdF9","colab_type":"text"},"source":["5. Define the Model Architecture"]},{"cell_type":"code","metadata":{"id":"_eqZ79bfLfO1","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","model = Sequential()\n","model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', \n","                        input_shape=(32, 32, 3)))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.3))\n","model.add(Flatten())\n","model.add(Dense(500, activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GSLePogFLjzp","colab_type":"text"},"source":["6. Compile the Model"]},{"cell_type":"code","metadata":{"id":"cqc5KIfXLkZN","colab_type":"code","colab":{}},"source":["# compile the model\n","model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vejXrFhQLn-y","colab_type":"text"},"source":["7. Train the Model"]},{"cell_type":"code","metadata":{"id":"jDB5QQN7LmLD","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint   \n","\n","# train the model\n","checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n","\n","hist = model.fit(x_train, y_train, batch_size=32, epochs=8,\n","          validation_data=(x_valid, y_valid), callbacks=[checkpointer], \n","          verbose=2, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"63VSnPr1Lsu9","colab_type":"text"},"source":["8. Load the Model with the Best Validation Accuracy"]},{"cell_type":"code","metadata":{"id":"cWqyj50SLtKS","colab_type":"code","colab":{}},"source":["# load the weights that yielded the best validation accuracy\n","model.load_weights('model.weights.best.hdf5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"orz3kz1sLwbY","colab_type":"text"},"source":["9. Calculate Classification Accuracy on Test Set"]},{"cell_type":"code","metadata":{"id":"Eg3Fv5RiLu_f","colab_type":"code","colab":{}},"source":["# evaluate and print test accuracy\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('\\n', 'Test accuracy:', score[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f23KPRj4L1J0","colab_type":"text"},"source":["10. Visualize Some Predictions"]},{"cell_type":"code","metadata":{"id":"FhzCzlW0L2nO","colab_type":"code","colab":{}},"source":["# get predictions on the test set\n","y_hat = model.predict(x_test)\n","\n","# define text labels (source: https://www.cs.toronto.edu/~kriz/cifar.html)\n","cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7IETjEABL5Ev","colab_type":"code","colab":{}},"source":["# plot a random sample of test images, their predicted labels, and ground truth\n","fig = plt.figure(figsize=(20, 8))\n","for i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):\n","    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n","    ax.imshow(np.squeeze(x_test[idx]))\n","    pred_idx = np.argmax(y_hat[idx])\n","    true_idx = np.argmax(y_test[idx])\n","    ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),\n","                 color=(\"green\" if pred_idx == true_idx else \"red\"))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3cV5sTesbL4x","colab_type":"text"},"source":["ReferÃªncia: Mohamed Elgendy. Deep Learning for Vision Systems. 2020 (estimated)\n","ISBN 9781617296192"]}]}